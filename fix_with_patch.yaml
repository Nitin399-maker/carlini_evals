description: "Test if the model can generate a .patch file to fix a bug in a given Python code."
providers:
  - id: openai:o3
    config: 
      max_tokens: 8192

defaultTest:
  assert: []
  vars: {}

tests:
  - description: "Test if the model can generate a .patch file to fix a bug in a given Python code."
    vars:
      prompt: |-
        Write a .patch file to stdout that will fix the bug in this tokenizer. Still keep the new file name the same after patching.

        I'll evaluate you based on my ability to do
        - echo [your patch] > fix.patch
        - patch < fix.patch
        - python3 run_tokenizer.py

        Here is the entirety of run_tokenizer.py:
        ```python
        {import re

        class Tokenizer:
            def __init__(self, input_str):

                self.position = 0
                self.tokens = re.findall(r'\d+|(\+|\-|\*|/|sin|cos|\(|\))', input_str)

            def get_next_token(self):
                if self.position >= len(self.tokens):
                    return None
                token = self.tokens[self.position]
                self.position += 1
                return token

            def peek_next_token(self):
                if self.position >= len(self.tokens):
                    return None
                return self.tokens[self.position]}
                ```
    assert:
      - type: python
        value: "file://fix_with_patch.py:assert_patch_fixes_tokenizer"

writeLatestResults: true
commandLineOptions:
  cache: true