
description: "Test if the model can identify and fix an issue with a tokenizer in a Python code snippet. Identifying the problem is in the regex, and fixing the regex, are both hard."
providers:
  - {id: openrouter:openai/o4-mini-high, config: { max_tokens: 8192 }}

defaultTest:
  assert: []
  vars: {}

tests:
  - description: "Test if the model can identify and fix an issue with a tokenizer in a Python code snippet. Identifying the problem is in the regex, and fixing the regex, are both hard."
    vars:
      prompt: |-
        Fix this tokenizer keeping it as similar as possible

        class Tokenizer:
        def __init__(self, input_str):
        self.tokens = re.findall(r'\d+|(\+|\-|\*|/|sin|cos|\(|\))', input_str)
        self.position = 0

        def get_next_token(self):
        if self.position >= len(self.tokens):
        return None
        token = self.tokens[self.position]
        self.position += 1
        return token

        def peek_next_token(self):
        if self.position >= len(self.tokens):
        return None
        return self.tokens[self.position]
    assert:
      - type: python
        value: "file://fix_tokenizer.py:assert_tokenizer_fix"

# Persist for the web viewer
writeLatestResults: true
# Ensure caching stays on
commandLineOptions:
  cache: true
